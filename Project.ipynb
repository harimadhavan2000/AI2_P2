{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Project: Classifying buildings post-Hurricane\n",
                "Univ.AI <br>\n",
                "AI-2 Cohort-4"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## [DATASET](https://drive.google.com/file/d/1EH3p84xKMs_2m4ISSR7aHOQz61yxIv8L/view?usp=sharing)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Names of the people who worked on the project:"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Link to presentation: <br>\n",
                "Link to slides: <br>\n",
                "Link to poster: <br>\n",
                "Link to notebook: <br>"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introduction\n",
                "After a hurrican in populated as well as sparse areas of human settlements, the very next thing after human rescue is the damage assessment. This is very critical for emergence managers as it helps them in efficint response and proper resource allocation. The only way for doing this is using ground survey or drones to manually quantify the number of flooded or damaged buildings. But this process being highly labour intensive and time taking, other efficint and faster methods have to be developed."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After a hurrican in populated as well as sparse areas of human settlements, the very next thing after human rescue is the damage assessment. This is very critical for emergence managers as it helps them in efficint response and proper resource allocation. The only way for doing this is using ground survey or drones to manually quantify the number of flooded or damaged buildings. But this process being highly labour intensive and time taking, other efficint and faster methods have to be developed.\n",
                "\n",
                "New Microsoft PowerPoint Presentation2w.jpg\n",
                "Having access to satellite imagery, its capabilities can easily be harnessed for this task. We can take satellite images of hurricane damaged areas, extract square size images containing one or group of buildings (using building coordinates) and use those square images to train a neural netwrok which can easily predict which building is damaged and which is not, how many buildings in a locality is damaged, etc. for any new satellite images of a particular area. This method will be cost efficint, easier and way faster and will help emergency managers accurately plan the resource requirement and efficiently distribute resources to those in need.\n",
                "In this notebook, we have used the square images of buildings in hurricane hit areas (which has been already extracted from satellite images) to train our model, to see how much accurate a deep learning model can be in classifying damaged and not-damaged buildings, and drawing inferences as to whether this method can be used in the post-hurricane emergency situation."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Our main focus in this notebook is to see how different SOTA models perform on the given dataset for the task of classification, compare them with our custom built model and understand which part of the image any CNN model usually focusses on to be able to classify it as damaged or not-damaged.\n",
                "\n",
                "Following is the broader description of the work carried out in this notebook:\n",
                "\n",
                "Creating an image data pipeline: To access images as datasets, do necessary transformations and prefetching for optimal utilization computing resourses.\n",
                "Building model architecture: Creating layer by layer whole CNN network in case of custom model or importing a SOTA model, customizing it and compiling it on MultiOptimizer.\n",
                "Training of model using the dataset\n",
                "Extracting inferences and comparison of model performaces: For both balanced and unbalanced test sets.\n",
                "Visualzing which part of the image model uses to make its prediction: Using both Saliency Mapping and GradCam."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import certifi\n",
                "import urllib3  # For handling https certificate verification \n",
                "import requests\n",
                "import zipfile\n",
                "import shutil\n",
                "import json\n",
                "import time\n",
                "import sys\n",
                "import cv2\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from scipy.signal import convolve2d\n",
                "import scipy.ndimage as ndimage\n",
                "import subprocess\n",
                "from PIL import Image\n",
                "from matplotlib import cm\n",
                "from matplotlib import pyplot\n",
                "import matplotlib.pyplot as plt\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2022-12-26 07:35:34.445238: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
                        "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2022-12-26 07:35:37.294334: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/munch/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
                        "2022-12-26 07:35:37.294933: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/munch/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
                        "2022-12-26 07:35:37.294968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
                    ]
                }
            ],
            "source": [
                "import keras\n",
                "import os, shutil\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from keras.models import load_model\n",
                "from keras import layers\n",
                "from keras import models\n",
                "from keras.preprocessing.image import ImageDataGenerator\n",
                "from keras import optimizers\n",
                "from keras.preprocessing import image\n",
                "from keras.layers import LeakyReLU\n",
                "from keras.regularizers import l2\n",
                "from keras import optimizers\n",
                "from keras.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "train_damage_dir = 'data/train_another/damage'\n",
                "validation_damage_dir = 'data/validation_another/damage'\n",
                "test_damage_dir = 'data/test/damage'\n",
                "test_another_damage_dir = 'data/test_another/damage'\n",
                "\n",
                "\n",
                "train_nodamage_dir = 'data/train_another/no_damage'\n",
                "validation_nodamage_dir = 'data/validation_another/no_damage'\n",
                "test_nodamage_dir = 'data/test/no_damage'\n",
                "test_another_nodamage_dir = 'data/test_another/no_damage'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2022-12-25 20:46:12.456137: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: \"sequential\"\n",
                        "_________________________________________________________________\n",
                        " Layer (type)                Output Shape              Param #   \n",
                        "=================================================================\n",
                        " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
                        "                                                                 \n",
                        " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
                        " )                                                               \n",
                        "                                                                 \n",
                        " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
                        "                                                                 \n",
                        " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
                        " 2D)                                                             \n",
                        "                                                                 \n",
                        " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
                        "                                                                 \n",
                        " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
                        " 2D)                                                             \n",
                        "                                                                 \n",
                        " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
                        "                                                                 \n",
                        " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
                        " 2D)                                                             \n",
                        "                                                                 \n",
                        " flatten (Flatten)           (None, 6272)              0         \n",
                        "                                                                 \n",
                        " dropout (Dropout)           (None, 6272)              0         \n",
                        "                                                                 \n",
                        " dense (Dense)               (None, 512)               3211776   \n",
                        "                                                                 \n",
                        " dense_1 (Dense)             (None, 1)                 513       \n",
                        "                                                                 \n",
                        "=================================================================\n",
                        "Total params: 3,453,121\n",
                        "Trainable params: 3,453,121\n",
                        "Non-trainable params: 0\n",
                        "_________________________________________________________________\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2022-12-25 20:46:12.507544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-25 20:46:12.507615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-25 20:46:12.508206: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
                        "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2022-12-25 20:46:12.527050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-25 20:46:12.527136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-25 20:46:12.527181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-25 20:46:13.921596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-25 20:46:13.921821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-25 20:46:13.921836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
                        "2022-12-25 20:46:13.921891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-25 20:46:13.921934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4577 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
                    ]
                }
            ],
            "source": [
                "# we need to create a convolutional neural netowrk to calssify a series of satellite images of cyclone damaged buildings into\n",
                "# damged and non-damged. these are the only two classes we are interested in.\n",
                "# use various strategies to improve the accuracy of the model, such as Adam, Drop out, Batch Normalization\n",
                "# also use max pooling appropriately in the network\n",
                "# the input shape of the images is 150x150x3\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "model = models.Sequential()\n",
                "model.add(layers.Conv2D(32,(3,3), activation = 'relu', input_shape = (150,150,3)))\n",
                "model.add(layers.MaxPooling2D((2,2)))\n",
                "model.add(layers.Conv2D(64,(3,3), activation = 'relu'))\n",
                "model.add(layers.MaxPooling2D((2,2)))\n",
                "model.add(layers.Conv2D(128,(3,3), activation = 'relu'))\n",
                "model.add(layers.MaxPooling2D((2,2)))\n",
                "model.add(layers.Conv2D(128,(3,3), activation = 'relu'))\n",
                "model.add(layers.MaxPooling2D((2,2)))\n",
                "model.add(layers.Flatten())\n",
                "model.add(layers.Dropout(0.5))\n",
                "model.add(layers.Dense(512, activation = 'relu'))\n",
                "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
                "model.summary() \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/munch/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
                        "  super().__init__(name, **kwargs)\n"
                    ]
                }
            ],
            "source": [
                "#compile the model, use the adam optimizer and binary cross entropy loss function\n",
                "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.Adam(lr = 1e-4), metrics = ['acc'])\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 10000 images belonging to 2 classes.\n",
                        "Found 2000 images belonging to 2 classes.\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "#normalize the image pixel value to be between 0 and 1\n",
                "train_datagen = ImageDataGenerator(rescale=1./255)\n",
                "test_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "train_generator = train_datagen.flow_from_directory(\n",
                "                    'data/train_another', \n",
                "                    target_size = (150,150),\n",
                "                    batch_size = 20,\n",
                "                    class_mode = 'binary')\n",
                "validation_generator = test_datagen.flow_from_directory(\n",
                "                    'data/validation_another',\n",
                "                    target_size = (150,150),\n",
                "                    batch_size = 20,\n",
                "                    class_mode = 'binary')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 9000 images belonging to 2 classes.\n"
                    ]
                }
            ],
            "source": [
                "test_gen = ImageDataGenerator(rescale=1./255)\n",
                "test_data = test_gen.flow_from_directory(\n",
                "    'data/test_another',\n",
                "    target_size = (150,150),\n",
                "    batch_size = 20,\n",
                "    class_mode = 'binary',\n",
                ")       "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_966/1049514492.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
                        "  model_1.evaluate_generator(test_data, steps=50)\n",
                        "2022-12-26 07:44:08.004255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[0.08870566636323929, 0.9660000205039978]"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model_1.evaluate_generator(test_data, steps=50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['loss', 'acc']"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model_1.metrics_names"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_966/1573621018.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
                        "  model_2.evaluate_generator(test_data, steps=50)\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[0.10183204710483551, 0.9629999995231628]"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model_2.evaluate_generator(test_data, steps=50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_966/1196173062.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
                        "  model_3.evaluate_generator(test_data, steps=50)\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[0.15321125090122223, 0.9390000104904175, 0.9065420627593994]"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model_3.evaluate_generator(test_data, steps=50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_27563/687701678.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
                        "  history = model.fit_generator(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/50\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2022-12-25 20:46:21.099009: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8401\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "100/100 [==============================] - 37s 345ms/step - loss: 0.6792 - acc: 0.5625 - val_loss: 0.6227 - val_acc: 0.8210\n",
                        "Epoch 2/50\n",
                        "100/100 [==============================] - 29s 291ms/step - loss: 0.5267 - acc: 0.7625 - val_loss: 0.4087 - val_acc: 0.8310\n",
                        "Epoch 3/50\n",
                        "100/100 [==============================] - 30s 297ms/step - loss: 0.4391 - acc: 0.8180 - val_loss: 0.3945 - val_acc: 0.8490\n",
                        "Epoch 4/50\n",
                        "100/100 [==============================] - 29s 286ms/step - loss: 0.4117 - acc: 0.8265 - val_loss: 0.3725 - val_acc: 0.8550\n",
                        "Epoch 5/50\n",
                        "100/100 [==============================] - 28s 281ms/step - loss: 0.3953 - acc: 0.8460 - val_loss: 0.3428 - val_acc: 0.8670\n",
                        "Epoch 6/50\n",
                        "100/100 [==============================] - 29s 294ms/step - loss: 0.3402 - acc: 0.8650 - val_loss: 0.3234 - val_acc: 0.8830\n",
                        "Epoch 7/50\n",
                        "100/100 [==============================] - 28s 282ms/step - loss: 0.3540 - acc: 0.8575 - val_loss: 0.3470 - val_acc: 0.8620\n",
                        "Epoch 8/50\n",
                        "100/100 [==============================] - 30s 295ms/step - loss: 0.2919 - acc: 0.8970 - val_loss: 0.2410 - val_acc: 0.9060\n",
                        "Epoch 9/50\n",
                        "100/100 [==============================] - 29s 288ms/step - loss: 0.2373 - acc: 0.9085 - val_loss: 0.2912 - val_acc: 0.8980\n",
                        "Epoch 10/50\n",
                        "100/100 [==============================] - 29s 294ms/step - loss: 0.2518 - acc: 0.9040 - val_loss: 0.1863 - val_acc: 0.9270\n",
                        "Epoch 11/50\n",
                        "100/100 [==============================] - 30s 299ms/step - loss: 0.2357 - acc: 0.9095 - val_loss: 0.2624 - val_acc: 0.9090\n",
                        "Epoch 12/50\n",
                        "100/100 [==============================] - 29s 293ms/step - loss: 0.2172 - acc: 0.9150 - val_loss: 0.1710 - val_acc: 0.9310\n",
                        "Epoch 13/50\n",
                        "100/100 [==============================] - 28s 284ms/step - loss: 0.1800 - acc: 0.9240 - val_loss: 0.1946 - val_acc: 0.9180\n",
                        "Epoch 14/50\n",
                        "100/100 [==============================] - 28s 282ms/step - loss: 0.1889 - acc: 0.9250 - val_loss: 0.2915 - val_acc: 0.8910\n",
                        "Epoch 15/50\n",
                        "100/100 [==============================] - 28s 284ms/step - loss: 0.1746 - acc: 0.9295 - val_loss: 0.1712 - val_acc: 0.9350\n",
                        "Epoch 16/50\n",
                        "100/100 [==============================] - 29s 287ms/step - loss: 0.1713 - acc: 0.9330 - val_loss: 0.1407 - val_acc: 0.9360\n",
                        "Epoch 17/50\n",
                        "100/100 [==============================] - 29s 292ms/step - loss: 0.1484 - acc: 0.9405 - val_loss: 0.1420 - val_acc: 0.9460\n",
                        "Epoch 18/50\n",
                        "100/100 [==============================] - 28s 279ms/step - loss: 0.1633 - acc: 0.9345 - val_loss: 0.1314 - val_acc: 0.9440\n",
                        "Epoch 19/50\n",
                        "100/100 [==============================] - 28s 281ms/step - loss: 0.1476 - acc: 0.9430 - val_loss: 0.1406 - val_acc: 0.9410\n",
                        "Epoch 20/50\n",
                        "100/100 [==============================] - 28s 282ms/step - loss: 0.1309 - acc: 0.9450 - val_loss: 0.1027 - val_acc: 0.9650\n",
                        "Epoch 21/50\n",
                        "100/100 [==============================] - 28s 283ms/step - loss: 0.1214 - acc: 0.9490 - val_loss: 0.1437 - val_acc: 0.9410\n",
                        "Epoch 22/50\n",
                        "100/100 [==============================] - 28s 276ms/step - loss: 0.1424 - acc: 0.9445 - val_loss: 0.1160 - val_acc: 0.9510\n",
                        "Epoch 23/50\n",
                        "100/100 [==============================] - 28s 275ms/step - loss: 0.1131 - acc: 0.9535 - val_loss: 0.1173 - val_acc: 0.9500\n",
                        "Epoch 24/50\n",
                        "100/100 [==============================] - 29s 291ms/step - loss: 0.1066 - acc: 0.9630 - val_loss: 0.1152 - val_acc: 0.9530\n",
                        "Epoch 25/50\n",
                        "100/100 [==============================] - 29s 286ms/step - loss: 0.1144 - acc: 0.9560 - val_loss: 0.1216 - val_acc: 0.9540\n",
                        "Epoch 26/50\n",
                        "100/100 [==============================] - 30s 297ms/step - loss: 0.1117 - acc: 0.9595 - val_loss: 0.1289 - val_acc: 0.9490\n",
                        "Epoch 27/50\n",
                        "100/100 [==============================] - 28s 281ms/step - loss: 0.1347 - acc: 0.9495 - val_loss: 0.1797 - val_acc: 0.9360\n",
                        "Epoch 28/50\n",
                        "100/100 [==============================] - 30s 299ms/step - loss: 0.1377 - acc: 0.9450 - val_loss: 0.1156 - val_acc: 0.9530\n",
                        "Epoch 29/50\n",
                        "100/100 [==============================] - 31s 306ms/step - loss: 0.1047 - acc: 0.9610 - val_loss: 0.1071 - val_acc: 0.9590\n",
                        "Epoch 30/50\n",
                        "100/100 [==============================] - 31s 307ms/step - loss: 0.0909 - acc: 0.9630 - val_loss: 0.1318 - val_acc: 0.9480\n",
                        "Epoch 31/50\n",
                        "100/100 [==============================] - 32s 317ms/step - loss: 0.1211 - acc: 0.9540 - val_loss: 0.1135 - val_acc: 0.9540\n",
                        "Epoch 32/50\n",
                        "100/100 [==============================] - 46s 462ms/step - loss: 0.1167 - acc: 0.9505 - val_loss: 0.0964 - val_acc: 0.9620\n",
                        "Epoch 33/50\n",
                        "100/100 [==============================] - 36s 365ms/step - loss: 0.0832 - acc: 0.9640 - val_loss: 0.1040 - val_acc: 0.9610\n",
                        "Epoch 34/50\n",
                        "100/100 [==============================] - 31s 307ms/step - loss: 0.0844 - acc: 0.9690 - val_loss: 0.1117 - val_acc: 0.9650\n",
                        "Epoch 35/50\n",
                        "100/100 [==============================] - 29s 286ms/step - loss: 0.0887 - acc: 0.9660 - val_loss: 0.1141 - val_acc: 0.9570\n",
                        "Epoch 36/50\n",
                        "100/100 [==============================] - 30s 296ms/step - loss: 0.0933 - acc: 0.9640 - val_loss: 0.1348 - val_acc: 0.9490\n",
                        "Epoch 37/50\n",
                        "100/100 [==============================] - 29s 292ms/step - loss: 0.0990 - acc: 0.9655 - val_loss: 0.1303 - val_acc: 0.9510\n",
                        "Epoch 38/50\n",
                        "100/100 [==============================] - 30s 303ms/step - loss: 0.0895 - acc: 0.9665 - val_loss: 0.1035 - val_acc: 0.9650\n",
                        "Epoch 39/50\n",
                        "100/100 [==============================] - 29s 290ms/step - loss: 0.0860 - acc: 0.9670 - val_loss: 0.1073 - val_acc: 0.9620\n",
                        "Epoch 40/50\n",
                        "100/100 [==============================] - 31s 309ms/step - loss: 0.0878 - acc: 0.9640 - val_loss: 0.1092 - val_acc: 0.9620\n",
                        "Epoch 41/50\n",
                        "100/100 [==============================] - 30s 296ms/step - loss: 0.0910 - acc: 0.9630 - val_loss: 0.1510 - val_acc: 0.9430\n",
                        "Epoch 42/50\n",
                        "100/100 [==============================] - 31s 309ms/step - loss: 0.1042 - acc: 0.9560 - val_loss: 0.1045 - val_acc: 0.9670\n",
                        "Epoch 43/50\n",
                        "100/100 [==============================] - 30s 298ms/step - loss: 0.0966 - acc: 0.9620 - val_loss: 0.1015 - val_acc: 0.9570\n",
                        "Epoch 44/50\n",
                        "100/100 [==============================] - 30s 300ms/step - loss: 0.0782 - acc: 0.9680 - val_loss: 0.0958 - val_acc: 0.9590\n",
                        "Epoch 45/50\n",
                        "100/100 [==============================] - 33s 311ms/step - loss: 0.0784 - acc: 0.9685 - val_loss: 0.0753 - val_acc: 0.9730\n",
                        "Epoch 46/50\n",
                        "100/100 [==============================] - 28s 279ms/step - loss: 0.0794 - acc: 0.9665 - val_loss: 0.0957 - val_acc: 0.9670\n",
                        "Epoch 47/50\n",
                        "100/100 [==============================] - 27s 274ms/step - loss: 0.0969 - acc: 0.9620 - val_loss: 0.0784 - val_acc: 0.9740\n",
                        "Epoch 48/50\n",
                        "100/100 [==============================] - 29s 287ms/step - loss: 0.0711 - acc: 0.9690 - val_loss: 0.0847 - val_acc: 0.9740\n",
                        "Epoch 49/50\n",
                        "100/100 [==============================] - 29s 289ms/step - loss: 0.0754 - acc: 0.9705 - val_loss: 0.0923 - val_acc: 0.9670\n",
                        "Epoch 50/50\n",
                        "100/100 [==============================] - 29s 288ms/step - loss: 0.0876 - acc: 0.9680 - val_loss: 0.0903 - val_acc: 0.9630\n"
                    ]
                }
            ],
            "source": [
                "history = model.fit_generator(\n",
                "            train_generator,\n",
                "            steps_per_epoch=100,\n",
                "            epochs=50,\n",
                "            validation_data=validation_generator,\n",
                "            validation_steps=50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "model.save('model.h5')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.save('model_with_dropout.h5')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "alex_model = keras.models.Sequential([\n",
                "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(150,150,3)),\n",
                "    keras.layers.BatchNormalization(),\n",
                "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
                "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
                "    keras.layers.BatchNormalization(),\n",
                "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
                "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
                "    keras.layers.BatchNormalization(),\n",
                "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
                "    keras.layers.BatchNormalization(),\n",
                "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
                "    keras.layers.BatchNormalization(),\n",
                "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
                "    keras.layers.Flatten(),\n",
                "    keras.layers.Dense(4096, activation='relu'),\n",
                "    keras.layers.Dropout(0.5),\n",
                "    keras.layers.Dense(4096, activation='relu'),\n",
                "    keras.layers.Dropout(0.5),\n",
                "    keras.layers.Dense(1, activation='sigmoid')\n",
                "])\n",
                "alex_model.compile(\n",
                "    optimizer=optimizers.Adam(learning_rate=0.000001),\n",
                "    loss='binary_crossentropy',\n",
                "    metrics=['accuracy','Recall']\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "callback = keras.callbacks.EarlyStopping(\n",
                "    monitor=\"val_loss\",\n",
                "    patience=5,\n",
                "    verbose=0,\n",
                "    restore_best_weights=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_880/773881726.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
                        "  history = alex_model.fit_generator(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/100\n",
                        "100/100 [==============================] - 33s 330ms/step - loss: 0.5444 - accuracy: 0.7750 - recall: 0.7629 - val_loss: 0.3608 - val_accuracy: 0.8520 - val_recall: 0.8509\n",
                        "Epoch 2/100\n",
                        "100/100 [==============================] - 33s 327ms/step - loss: 0.5709 - accuracy: 0.7790 - recall: 0.7820 - val_loss: 0.3683 - val_accuracy: 0.8550 - val_recall: 0.8290\n",
                        "Epoch 3/100\n",
                        "100/100 [==============================] - 32s 323ms/step - loss: 0.5466 - accuracy: 0.7840 - recall: 0.7711 - val_loss: 0.3283 - val_accuracy: 0.8620 - val_recall: 0.8523\n",
                        "Epoch 4/100\n",
                        "100/100 [==============================] - 32s 321ms/step - loss: 0.5294 - accuracy: 0.7975 - recall: 0.7801 - val_loss: 0.3228 - val_accuracy: 0.8690 - val_recall: 0.8770\n",
                        "Epoch 5/100\n",
                        "100/100 [==============================] - 33s 326ms/step - loss: 0.5148 - accuracy: 0.8050 - recall: 0.8129 - val_loss: 0.3473 - val_accuracy: 0.8660 - val_recall: 0.8320\n",
                        "Epoch 6/100\n",
                        "100/100 [==============================] - 32s 319ms/step - loss: 0.5341 - accuracy: 0.7955 - recall: 0.7913 - val_loss: 0.3162 - val_accuracy: 0.8760 - val_recall: 0.8645\n",
                        "Epoch 7/100\n",
                        "100/100 [==============================] - 32s 318ms/step - loss: 0.5148 - accuracy: 0.8025 - recall: 0.8080 - val_loss: 0.3216 - val_accuracy: 0.8890 - val_recall: 0.8617\n",
                        "Epoch 8/100\n",
                        "100/100 [==============================] - 32s 318ms/step - loss: 0.4740 - accuracy: 0.8205 - recall: 0.8146 - val_loss: 0.3170 - val_accuracy: 0.8870 - val_recall: 0.8958\n",
                        "Epoch 9/100\n",
                        "100/100 [==============================] - 32s 316ms/step - loss: 0.4475 - accuracy: 0.8315 - recall: 0.8368 - val_loss: 0.3178 - val_accuracy: 0.8830 - val_recall: 0.8669\n",
                        "Epoch 10/100\n",
                        "100/100 [==============================] - 32s 318ms/step - loss: 0.4463 - accuracy: 0.8180 - recall: 0.8114 - val_loss: 0.3086 - val_accuracy: 0.8790 - val_recall: 0.8566\n",
                        "Epoch 11/100\n",
                        "100/100 [==============================] - 32s 318ms/step - loss: 0.4523 - accuracy: 0.8255 - recall: 0.8082 - val_loss: 0.3029 - val_accuracy: 0.8870 - val_recall: 0.8762\n",
                        "Epoch 12/100\n",
                        "100/100 [==============================] - 32s 324ms/step - loss: 0.4583 - accuracy: 0.8275 - recall: 0.8247 - val_loss: 0.3052 - val_accuracy: 0.8890 - val_recall: 0.8540\n",
                        "Epoch 13/100\n",
                        "100/100 [==============================] - 32s 322ms/step - loss: 0.4715 - accuracy: 0.8200 - recall: 0.8141 - val_loss: 0.3031 - val_accuracy: 0.8870 - val_recall: 0.8777\n",
                        "Epoch 14/100\n",
                        "100/100 [==============================] - 32s 321ms/step - loss: 0.4006 - accuracy: 0.8360 - recall: 0.8314 - val_loss: 0.3156 - val_accuracy: 0.8760 - val_recall: 0.8516\n",
                        "Epoch 15/100\n",
                        "100/100 [==============================] - 32s 319ms/step - loss: 0.3959 - accuracy: 0.8505 - recall: 0.8587 - val_loss: 0.2983 - val_accuracy: 0.8870 - val_recall: 0.8653\n",
                        "Epoch 16/100\n",
                        "100/100 [==============================] - 33s 334ms/step - loss: 0.4160 - accuracy: 0.8375 - recall: 0.8338 - val_loss: 0.3270 - val_accuracy: 0.8760 - val_recall: 0.8490\n",
                        "Epoch 17/100\n",
                        "100/100 [==============================] - 32s 320ms/step - loss: 0.4295 - accuracy: 0.8320 - recall: 0.8309 - val_loss: 0.3027 - val_accuracy: 0.8900 - val_recall: 0.8760\n",
                        "Epoch 18/100\n",
                        "100/100 [==============================] - 32s 320ms/step - loss: 0.4150 - accuracy: 0.8450 - recall: 0.8361 - val_loss: 0.2684 - val_accuracy: 0.8970 - val_recall: 0.8869\n",
                        "Epoch 19/100\n",
                        "100/100 [==============================] - 34s 339ms/step - loss: 0.3874 - accuracy: 0.8530 - recall: 0.8601 - val_loss: 0.2941 - val_accuracy: 0.8880 - val_recall: 0.8745\n",
                        "Epoch 20/100\n",
                        "100/100 [==============================] - 33s 326ms/step - loss: 0.3994 - accuracy: 0.8430 - recall: 0.8327 - val_loss: 0.2927 - val_accuracy: 0.8920 - val_recall: 0.8613\n",
                        "Epoch 21/100\n",
                        "100/100 [==============================] - 33s 326ms/step - loss: 0.3926 - accuracy: 0.8505 - recall: 0.8560 - val_loss: 0.2973 - val_accuracy: 0.8850 - val_recall: 0.8476\n",
                        "Epoch 22/100\n",
                        "100/100 [==============================] - 33s 326ms/step - loss: 0.3922 - accuracy: 0.8490 - recall: 0.8545 - val_loss: 0.2944 - val_accuracy: 0.8870 - val_recall: 0.8677\n",
                        "Epoch 23/100\n",
                        "100/100 [==============================] - 33s 333ms/step - loss: 0.3889 - accuracy: 0.8520 - recall: 0.8502 - val_loss: 0.2533 - val_accuracy: 0.9060 - val_recall: 0.9082\n",
                        "Epoch 24/100\n",
                        "100/100 [==============================] - 33s 331ms/step - loss: 0.3536 - accuracy: 0.8635 - recall: 0.8766 - val_loss: 0.2964 - val_accuracy: 0.8900 - val_recall: 0.8653\n",
                        "Epoch 25/100\n",
                        "100/100 [==============================] - 33s 325ms/step - loss: 0.3470 - accuracy: 0.8530 - recall: 0.8541 - val_loss: 0.2625 - val_accuracy: 0.8980 - val_recall: 0.8873\n",
                        "Epoch 26/100\n",
                        "100/100 [==============================] - 33s 326ms/step - loss: 0.3647 - accuracy: 0.8565 - recall: 0.8488 - val_loss: 0.2748 - val_accuracy: 0.8970 - val_recall: 0.8725\n",
                        "Epoch 27/100\n",
                        "100/100 [==============================] - 33s 328ms/step - loss: 0.3395 - accuracy: 0.8670 - recall: 0.8678 - val_loss: 0.2764 - val_accuracy: 0.8940 - val_recall: 0.8465\n",
                        "Epoch 28/100\n",
                        "100/100 [==============================] - 33s 328ms/step - loss: 0.3289 - accuracy: 0.8710 - recall: 0.8735 - val_loss: 0.2602 - val_accuracy: 0.9000 - val_recall: 0.8762\n",
                        "Epoch 29/100\n",
                        "100/100 [==============================] - 33s 335ms/step - loss: 0.3431 - accuracy: 0.8755 - recall: 0.8695 - val_loss: 0.2490 - val_accuracy: 0.9030 - val_recall: 0.8955\n",
                        "Epoch 30/100\n",
                        "100/100 [==============================] - 32s 320ms/step - loss: 0.3685 - accuracy: 0.8580 - recall: 0.8663 - val_loss: 0.2519 - val_accuracy: 0.9010 - val_recall: 0.8600\n",
                        "Epoch 31/100\n",
                        "100/100 [==============================] - 33s 327ms/step - loss: 0.3653 - accuracy: 0.8585 - recall: 0.8525 - val_loss: 0.2726 - val_accuracy: 0.8960 - val_recall: 0.8477\n",
                        "Epoch 32/100\n",
                        "100/100 [==============================] - 32s 317ms/step - loss: 0.3612 - accuracy: 0.8640 - recall: 0.8576 - val_loss: 0.2423 - val_accuracy: 0.9040 - val_recall: 0.8980\n",
                        "Epoch 33/100\n",
                        "100/100 [==============================] - 32s 323ms/step - loss: 0.3438 - accuracy: 0.8710 - recall: 0.8812 - val_loss: 0.2377 - val_accuracy: 0.9110 - val_recall: 0.9064\n",
                        "Epoch 34/100\n",
                        "100/100 [==============================] - 32s 317ms/step - loss: 0.3342 - accuracy: 0.8730 - recall: 0.8764 - val_loss: 0.2547 - val_accuracy: 0.8990 - val_recall: 0.8816\n",
                        "Epoch 35/100\n",
                        "100/100 [==============================] - 32s 324ms/step - loss: 0.3153 - accuracy: 0.8745 - recall: 0.8830 - val_loss: 0.2728 - val_accuracy: 0.8960 - val_recall: 0.8689\n",
                        "Epoch 36/100\n",
                        "100/100 [==============================] - 31s 313ms/step - loss: 0.3494 - accuracy: 0.8590 - recall: 0.8629 - val_loss: 0.2721 - val_accuracy: 0.9000 - val_recall: 0.8455\n",
                        "Epoch 37/100\n",
                        "100/100 [==============================] - 32s 316ms/step - loss: 0.3141 - accuracy: 0.8915 - recall: 0.8818 - val_loss: 0.2546 - val_accuracy: 0.9030 - val_recall: 0.8859\n",
                        "Epoch 38/100\n",
                        "100/100 [==============================] - 32s 324ms/step - loss: 0.3002 - accuracy: 0.8825 - recall: 0.8804 - val_loss: 0.2171 - val_accuracy: 0.9180 - val_recall: 0.9225\n",
                        "Epoch 39/100\n",
                        "100/100 [==============================] - 32s 320ms/step - loss: 0.3217 - accuracy: 0.8630 - recall: 0.8566 - val_loss: 0.2194 - val_accuracy: 0.9230 - val_recall: 0.9041\n",
                        "Epoch 40/100\n",
                        "100/100 [==============================] - 32s 324ms/step - loss: 0.3285 - accuracy: 0.8710 - recall: 0.8755 - val_loss: 0.2400 - val_accuracy: 0.9120 - val_recall: 0.9168\n",
                        "Epoch 41/100\n",
                        "100/100 [==============================] - 32s 324ms/step - loss: 0.3002 - accuracy: 0.8850 - recall: 0.8843 - val_loss: 0.2405 - val_accuracy: 0.9120 - val_recall: 0.8917\n",
                        "Epoch 42/100\n",
                        "100/100 [==============================] - 32s 323ms/step - loss: 0.3155 - accuracy: 0.8795 - recall: 0.8886 - val_loss: 0.2476 - val_accuracy: 0.9120 - val_recall: 0.9000\n",
                        "Epoch 43/100\n",
                        "100/100 [==============================] - 32s 319ms/step - loss: 0.2832 - accuracy: 0.8805 - recall: 0.8732 - val_loss: 0.2377 - val_accuracy: 0.9080 - val_recall: 0.9130\n",
                        "Epoch 44/100\n",
                        "100/100 [==============================] - 30s 305ms/step - loss: 0.2506 - accuracy: 0.8965 - recall: 0.9037 - val_loss: 0.2370 - val_accuracy: 0.9060 - val_recall: 0.8976\n",
                        "Epoch 45/100\n",
                        "100/100 [==============================] - 30s 296ms/step - loss: 0.2947 - accuracy: 0.8865 - recall: 0.8892 - val_loss: 0.2288 - val_accuracy: 0.9180 - val_recall: 0.8987\n",
                        "Epoch 46/100\n",
                        "100/100 [==============================] - 29s 291ms/step - loss: 0.2737 - accuracy: 0.8975 - recall: 0.8928 - val_loss: 0.2346 - val_accuracy: 0.9200 - val_recall: 0.9126\n",
                        "Epoch 47/100\n",
                        "100/100 [==============================] - 29s 292ms/step - loss: 0.2542 - accuracy: 0.9005 - recall: 0.8964 - val_loss: 0.2068 - val_accuracy: 0.9220 - val_recall: 0.9232\n",
                        "Epoch 48/100\n",
                        "100/100 [==============================] - 29s 288ms/step - loss: 0.2691 - accuracy: 0.8990 - recall: 0.9097 - val_loss: 0.2243 - val_accuracy: 0.9190 - val_recall: 0.8939\n",
                        "Epoch 49/100\n",
                        "100/100 [==============================] - 29s 293ms/step - loss: 0.2804 - accuracy: 0.8905 - recall: 0.8923 - val_loss: 0.2134 - val_accuracy: 0.9240 - val_recall: 0.9199\n",
                        "Epoch 50/100\n",
                        "100/100 [==============================] - 29s 289ms/step - loss: 0.2684 - accuracy: 0.9025 - recall: 0.8849 - val_loss: 0.2290 - val_accuracy: 0.9120 - val_recall: 0.8934\n",
                        "Epoch 51/100\n",
                        "100/100 [==============================] - 28s 276ms/step - loss: 0.2564 - accuracy: 0.8990 - recall: 0.9032 - val_loss: 0.2487 - val_accuracy: 0.9020 - val_recall: 0.8671\n",
                        "Epoch 52/100\n",
                        "100/100 [==============================] - 29s 287ms/step - loss: 0.2605 - accuracy: 0.9015 - recall: 0.8875 - val_loss: 0.2534 - val_accuracy: 0.9180 - val_recall: 0.9296\n",
                        "Epoch 53/100\n",
                        "100/100 [==============================] - 29s 285ms/step - loss: 0.2379 - accuracy: 0.9120 - recall: 0.9110 - val_loss: 0.2060 - val_accuracy: 0.9180 - val_recall: 0.9167\n",
                        "Epoch 54/100\n",
                        "100/100 [==============================] - 28s 285ms/step - loss: 0.2773 - accuracy: 0.8945 - recall: 0.9001 - val_loss: 0.2204 - val_accuracy: 0.9200 - val_recall: 0.8869\n",
                        "Epoch 55/100\n",
                        "100/100 [==============================] - 29s 286ms/step - loss: 0.2708 - accuracy: 0.8930 - recall: 0.8892 - val_loss: 0.2059 - val_accuracy: 0.9250 - val_recall: 0.9130\n",
                        "Epoch 56/100\n",
                        "100/100 [==============================] - 28s 280ms/step - loss: 0.2841 - accuracy: 0.8940 - recall: 0.8914 - val_loss: 0.2375 - val_accuracy: 0.9100 - val_recall: 0.8962\n",
                        "Epoch 57/100\n",
                        "100/100 [==============================] - 28s 280ms/step - loss: 0.2745 - accuracy: 0.8945 - recall: 0.8935 - val_loss: 0.2288 - val_accuracy: 0.9150 - val_recall: 0.9170\n",
                        "Epoch 58/100\n",
                        "100/100 [==============================] - 29s 290ms/step - loss: 0.2480 - accuracy: 0.8990 - recall: 0.8950 - val_loss: 0.2022 - val_accuracy: 0.9250 - val_recall: 0.9218\n",
                        "Epoch 59/100\n",
                        "100/100 [==============================] - 28s 279ms/step - loss: 0.2529 - accuracy: 0.9045 - recall: 0.9112 - val_loss: 0.1942 - val_accuracy: 0.9300 - val_recall: 0.9270\n",
                        "Epoch 60/100\n",
                        "100/100 [==============================] - 29s 289ms/step - loss: 0.2253 - accuracy: 0.9075 - recall: 0.9119 - val_loss: 0.2042 - val_accuracy: 0.9260 - val_recall: 0.9160\n",
                        "Epoch 61/100\n",
                        "100/100 [==============================] - 28s 284ms/step - loss: 0.2483 - accuracy: 0.9075 - recall: 0.9108 - val_loss: 0.2045 - val_accuracy: 0.9290 - val_recall: 0.9176\n",
                        "Epoch 62/100\n",
                        "100/100 [==============================] - 28s 284ms/step - loss: 0.2523 - accuracy: 0.8925 - recall: 0.8929 - val_loss: 0.2280 - val_accuracy: 0.9180 - val_recall: 0.8918\n",
                        "Epoch 63/100\n",
                        "100/100 [==============================] - 29s 286ms/step - loss: 0.2385 - accuracy: 0.9155 - recall: 0.9141 - val_loss: 0.2041 - val_accuracy: 0.9280 - val_recall: 0.9076\n",
                        "Epoch 64/100\n",
                        "100/100 [==============================] - 29s 295ms/step - loss: 0.2251 - accuracy: 0.9155 - recall: 0.9163 - val_loss: 0.2134 - val_accuracy: 0.9240 - val_recall: 0.9220\n",
                        "Epoch 65/100\n",
                        "100/100 [==============================] - 29s 285ms/step - loss: 0.2103 - accuracy: 0.9220 - recall: 0.9269 - val_loss: 0.2287 - val_accuracy: 0.9120 - val_recall: 0.9294\n",
                        "Epoch 66/100\n",
                        "100/100 [==============================] - 28s 285ms/step - loss: 0.2150 - accuracy: 0.9105 - recall: 0.9109 - val_loss: 0.1938 - val_accuracy: 0.9290 - val_recall: 0.9160\n",
                        "Epoch 67/100\n",
                        "100/100 [==============================] - 29s 290ms/step - loss: 0.2601 - accuracy: 0.9015 - recall: 0.8970 - val_loss: 0.1875 - val_accuracy: 0.9320 - val_recall: 0.9290\n",
                        "Epoch 68/100\n",
                        "100/100 [==============================] - 29s 292ms/step - loss: 0.1915 - accuracy: 0.9255 - recall: 0.9203 - val_loss: 0.1937 - val_accuracy: 0.9260 - val_recall: 0.9082\n",
                        "Epoch 69/100\n",
                        "100/100 [==============================] - 29s 294ms/step - loss: 0.1984 - accuracy: 0.9235 - recall: 0.9188 - val_loss: 0.2022 - val_accuracy: 0.9270 - val_recall: 0.9242\n",
                        "Epoch 70/100\n",
                        "100/100 [==============================] - 29s 287ms/step - loss: 0.2544 - accuracy: 0.8945 - recall: 0.8969 - val_loss: 0.1915 - val_accuracy: 0.9260 - val_recall: 0.9150\n",
                        "Epoch 71/100\n",
                        "100/100 [==============================] - 30s 296ms/step - loss: 0.1916 - accuracy: 0.9260 - recall: 0.9298 - val_loss: 0.1849 - val_accuracy: 0.9360 - val_recall: 0.9382\n",
                        "Epoch 72/100\n",
                        "100/100 [==============================] - 28s 281ms/step - loss: 0.2207 - accuracy: 0.9115 - recall: 0.9150 - val_loss: 0.1819 - val_accuracy: 0.9290 - val_recall: 0.9118\n",
                        "Epoch 73/100\n",
                        "100/100 [==============================] - 28s 285ms/step - loss: 0.2043 - accuracy: 0.9220 - recall: 0.9301 - val_loss: 0.2028 - val_accuracy: 0.9220 - val_recall: 0.9173\n",
                        "Epoch 74/100\n",
                        "100/100 [==============================] - 28s 279ms/step - loss: 0.2234 - accuracy: 0.9155 - recall: 0.9094 - val_loss: 0.2002 - val_accuracy: 0.9300 - val_recall: 0.9296\n",
                        "Epoch 75/100\n",
                        "100/100 [==============================] - 29s 290ms/step - loss: 0.1991 - accuracy: 0.9200 - recall: 0.9163 - val_loss: 0.1804 - val_accuracy: 0.9400 - val_recall: 0.9309\n",
                        "Epoch 76/100\n",
                        "100/100 [==============================] - 28s 285ms/step - loss: 0.1799 - accuracy: 0.9275 - recall: 0.9278 - val_loss: 0.1870 - val_accuracy: 0.9320 - val_recall: 0.9319\n",
                        "Epoch 77/100\n",
                        "100/100 [==============================] - 30s 297ms/step - loss: 0.2047 - accuracy: 0.9240 - recall: 0.9228 - val_loss: 0.1805 - val_accuracy: 0.9320 - val_recall: 0.9111\n",
                        "Epoch 78/100\n",
                        "100/100 [==============================] - 29s 286ms/step - loss: 0.2162 - accuracy: 0.9215 - recall: 0.9232 - val_loss: 0.1542 - val_accuracy: 0.9510 - val_recall: 0.9527\n",
                        "Epoch 79/100\n",
                        "100/100 [==============================] - 28s 283ms/step - loss: 0.1988 - accuracy: 0.9210 - recall: 0.9175 - val_loss: 0.2053 - val_accuracy: 0.9270 - val_recall: 0.9051\n",
                        "Epoch 80/100\n",
                        "100/100 [==============================] - 28s 281ms/step - loss: 0.2045 - accuracy: 0.9190 - recall: 0.9163 - val_loss: 0.1836 - val_accuracy: 0.9380 - val_recall: 0.9390\n",
                        "Epoch 81/100\n",
                        "100/100 [==============================] - 28s 276ms/step - loss: 0.1960 - accuracy: 0.9220 - recall: 0.9193 - val_loss: 0.1826 - val_accuracy: 0.9350 - val_recall: 0.9129\n",
                        "Epoch 82/100\n",
                        "100/100 [==============================] - 29s 286ms/step - loss: 0.2129 - accuracy: 0.9165 - recall: 0.9206 - val_loss: 0.1877 - val_accuracy: 0.9340 - val_recall: 0.9189\n",
                        "Epoch 83/100\n",
                        "100/100 [==============================] - 29s 291ms/step - loss: 0.2138 - accuracy: 0.9175 - recall: 0.9194 - val_loss: 0.1943 - val_accuracy: 0.9280 - val_recall: 0.9100\n",
                        "Epoch 84/100\n",
                        "100/100 [==============================] - 28s 285ms/step - loss: 0.1967 - accuracy: 0.9205 - recall: 0.9232 - val_loss: 0.1710 - val_accuracy: 0.9300 - val_recall: 0.9325\n",
                        "Epoch 85/100\n",
                        "100/100 [==============================] - 29s 289ms/step - loss: 0.1862 - accuracy: 0.9300 - recall: 0.9328 - val_loss: 0.1842 - val_accuracy: 0.9250 - val_recall: 0.8893\n",
                        "Epoch 86/100\n",
                        "100/100 [==============================] - 28s 281ms/step - loss: 0.1954 - accuracy: 0.9250 - recall: 0.9331 - val_loss: 0.1848 - val_accuracy: 0.9360 - val_recall: 0.9241\n",
                        "Epoch 87/100\n",
                        "100/100 [==============================] - 28s 278ms/step - loss: 0.1903 - accuracy: 0.9260 - recall: 0.9232 - val_loss: 0.1951 - val_accuracy: 0.9350 - val_recall: 0.9242\n",
                        "Epoch 88/100\n",
                        "100/100 [==============================] - 29s 287ms/step - loss: 0.1998 - accuracy: 0.9185 - recall: 0.9241 - val_loss: 0.1914 - val_accuracy: 0.9320 - val_recall: 0.9155\n",
                        "Epoch 89/100\n",
                        "100/100 [==============================] - 29s 290ms/step - loss: 0.1639 - accuracy: 0.9410 - recall: 0.9342 - val_loss: 0.2115 - val_accuracy: 0.9240 - val_recall: 0.9475\n",
                        "Epoch 90/100\n",
                        "100/100 [==============================] - 28s 282ms/step - loss: 0.2226 - accuracy: 0.9125 - recall: 0.9200 - val_loss: 0.1996 - val_accuracy: 0.9310 - val_recall: 0.9012\n",
                        "Epoch 91/100\n",
                        "100/100 [==============================] - 29s 287ms/step - loss: 0.1913 - accuracy: 0.9170 - recall: 0.9177 - val_loss: 0.1643 - val_accuracy: 0.9370 - val_recall: 0.9318\n",
                        "Epoch 92/100\n",
                        "100/100 [==============================] - 29s 284ms/step - loss: 0.1942 - accuracy: 0.9260 - recall: 0.9227 - val_loss: 0.1535 - val_accuracy: 0.9420 - val_recall: 0.9287\n",
                        "Epoch 93/100\n",
                        "100/100 [==============================] - 29s 289ms/step - loss: 0.1927 - accuracy: 0.9245 - recall: 0.9238 - val_loss: 0.1598 - val_accuracy: 0.9410 - val_recall: 0.9284\n",
                        "Epoch 94/100\n",
                        "100/100 [==============================] - 29s 295ms/step - loss: 0.1880 - accuracy: 0.9305 - recall: 0.9357 - val_loss: 0.2154 - val_accuracy: 0.9240 - val_recall: 0.9344\n",
                        "Epoch 95/100\n",
                        "100/100 [==============================] - 29s 287ms/step - loss: 0.1804 - accuracy: 0.9210 - recall: 0.9172 - val_loss: 0.1637 - val_accuracy: 0.9520 - val_recall: 0.9363\n",
                        "Epoch 96/100\n",
                        "100/100 [==============================] - 28s 283ms/step - loss: 0.2028 - accuracy: 0.9180 - recall: 0.9241 - val_loss: 0.1787 - val_accuracy: 0.9270 - val_recall: 0.9158\n",
                        "Epoch 97/100\n",
                        "100/100 [==============================] - 29s 285ms/step - loss: 0.1669 - accuracy: 0.9355 - recall: 0.9296 - val_loss: 0.1937 - val_accuracy: 0.9300 - val_recall: 0.8950\n",
                        "Epoch 98/100\n",
                        "100/100 [==============================] - 28s 279ms/step - loss: 0.1738 - accuracy: 0.9315 - recall: 0.9366 - val_loss: 0.1684 - val_accuracy: 0.9310 - val_recall: 0.9348\n",
                        "Epoch 99/100\n",
                        "100/100 [==============================] - 28s 277ms/step - loss: 0.1704 - accuracy: 0.9395 - recall: 0.9340 - val_loss: 0.1721 - val_accuracy: 0.9460 - val_recall: 0.9291\n",
                        "Epoch 100/100\n",
                        "100/100 [==============================] - 29s 288ms/step - loss: 0.1860 - accuracy: 0.9255 - recall: 0.9333 - val_loss: 0.2154 - val_accuracy: 0.9180 - val_recall: 0.9041\n"
                    ]
                }
            ],
            "source": [
                "history = alex_model.fit_generator(\n",
                "            train_generator,\n",
                "            steps_per_epoch=100,\n",
                "            epochs=100,\n",
                "            validation_data=validation_generator,\n",
                "            validation_steps=50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "alex_model.save('alex.h5')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2022-12-26 07:36:24.527482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-26 07:36:24.678593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-26 07:36:24.678713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-26 07:36:24.681325: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
                        "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2022-12-26 07:36:24.686351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-26 07:36:24.686894: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-26 07:36:24.687097: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-26 07:36:26.745007: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-26 07:36:26.746574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-26 07:36:26.746639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
                        "2022-12-26 07:36:26.746916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
                        "Your kernel may have been built without NUMA support.\n",
                        "2022-12-26 07:36:26.747691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4577 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
                    ]
                }
            ],
            "source": [
                "model_1 = load_model('model.h5')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_2 = load_model('model_with_dropout.h5')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_3 = load_model('alex.h5')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        },
        "vscode": {
            "interpreter": {
                "hash": "3751913ea9f5bd031e0b6a9f249a184a00fb379186ae8976a2500bce67b98d17"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
